{
 "metadata": {
  "name": "",
  "signature": "sha256:b4957e0259d7d76ef8228b99aed85dbe77ad652e9aee5c42614af16b53d2d1d1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "GETTING DATA FROM INSTAGRAM API"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Script for collecting data from Instagram API. \n",
      "\n",
      "Data stored in JSON format and have next specification:\n",
      "\n",
      "**media_general_info:** {media_id, comments_count, link, created_time, location, user_id, likes_count, media_type,  description, popular}\n",
      "\n",
      "***\n",
      "\n",
      "All data stored in **CSV** files and divided on **3** folders."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<span style=\"color:gray;\">** # Variables to specify **</span>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "CLIENT_ID = 'YOUR CLIENT ID HERE'\n",
      "ACCESS_TOKEN = 'YOUR TOKEN HERE'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<span style=\"color:gray;\">** # Import libraries **</span>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib2\n",
      "import json\n",
      "import csv\n",
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<span style=\"color:gray;\">** # Predefined functions **</span>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get JSON object with data from API instagram using specified URL address\n",
      "def get_data(url):\n",
      "    json_object = urllib2.urlopen(url.encode('utf-8'))\n",
      "    data = json.load (json_object)\n",
      "    return data\n",
      "\n",
      "# Change the structure of the data in the format we need\n",
      "def modify_data(data):\n",
      "    clr_data = []\n",
      "    for i in range(len(data)):\n",
      "        if data[i]['tags']: # Check if data have tags and store only with tags\n",
      "            media = {\n",
      "                        'media_id': data[i]['id'],\n",
      "                        'user_id': data[i]['user']['id'],\n",
      "                        'link': data[i]['link'],\n",
      "                        'created_time': data[i]['created_time'],\n",
      "                        'img_url': data[i]['images']['standard_resolution']['url'],\n",
      "                        'likes_count': data[i]['likes']['count'],\n",
      "                        'tags': data[i]['tags']\n",
      "                    }\n",
      "            clr_data.append(media)\n",
      "    return clr_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The number of users in instagram around 300kk. Separate the space for produce independent data on different machine."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "number_of_users = 300000000\n",
      "number_of_machines = 3\n",
      "search_space = number_of_users/number_of_machines # there is no need to round() because python 2.7 will return integer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list_user_id = []\n",
      "\n",
      "# Random generating of user id\n",
      "def generate_user_id(min_id, max_id):\n",
      "    global list_user_id\n",
      "    user_id = random.randint(min_id, max_id) # Get random user_id\n",
      "    if user_id in list_user_id: # If this id was used before\n",
      "        generate_user_id(min_id, max_id) # Generate another user_id\n",
      "    else:\n",
      "        return user_id\n",
      "\n",
      "# Save all users_id what have been seen\n",
      "def save_user_id(user_id):\n",
      "    list_user_id.append(user_id)\n",
      "\n",
      "# Store all data in big CSV file\n",
      "def store_in_big_csv(machine, data_for_storing):\n",
      "    file_name = \"All_Data_DB\" + str(machine)\n",
      "    # File path need to be changed \n",
      "    file_path = r\"C:\\Users\\Administrator\\Dropbox\\adeo_prj\\instagram-project\\DB_%s\\%s\" %(str(machine),file_name)\n",
      "    with open(file_path, \"ab\") as f:\n",
      "        # w = csv.writer(f)\n",
      "        for media in data_for_storing:\n",
      "            json.dump(media, f)\n",
      "            f.write('\\n') # Go to new line\n",
      "            # w.writerow([str(media)])\n",
      "\n",
      "# Store data in small CSV files, name of the file == user_id\n",
      "def store_in_user_csv(machine, user_id, data_for_storing):\n",
      "    file_name = str(user_id)\n",
      "    # File path need to be changed \n",
      "    file_path = r\"C:\\Users\\Administrator\\Dropbox\\adeo_prj\\instagram-project\\DB_%s\\%s\" %(str(machine),file_name)\n",
      "    with open(file_path, \"ab\") as f:\n",
      "        # w = csv.writer(f)\n",
      "        for media in data_for_storing:\n",
      "            json.dump(media, f)\n",
      "            f.write('\\n') # Go to new line\n",
      "            # w.writerow([str(media)])\n",
      "            \n",
      "# Save all seen user_ids with tags in file, for navigation\n",
      "def store_user_ids(machine, list_user_id):\n",
      "    file_name = \"UserList_machine_\" + str(machine)\n",
      "    # File path need to be changed \n",
      "    file_path = r\"C:\\Users\\Administrator\\Dropbox\\adeo_prj\\instagram-project\\DB_%s\\%s\" %(str(machine),file_name)\n",
      "    with open(file_path, \"ab\") as f:\n",
      "        for user_id in list_user_id:\n",
      "            f.write(\"%s\\n\" % str(user_id))\n",
      "            \n",
      "# Store data in csv file for analysis\n",
      "def store_data_for_analysis(machine, data_for_storing):\n",
      "    file_name = \"Analysis_DB\" + str(machine)\n",
      "    # File path need to be changed \n",
      "    file_path = r\"C:\\Users\\Administrator\\Dropbox\\adeo_prj\\instagram-project\\DB_%s\\%s\" %(str(machine),file_name)\n",
      "    with open(file_path, \"ab\") as f:\n",
      "        w = csv.writer(f)\n",
      "        #w.writerow([\"media_id\", \"user_id\", \"link\", \"created_time\", \"img_url\", \"likes_count\", \"tag\"])\n",
      "        for media in data_for_storing:\n",
      "            for tag in media['tags']:\n",
      "                w.writerow([\n",
      "                            media['media_id'],\n",
      "                            media['user_id'],\n",
      "                            media['link'],\n",
      "                            media['created_time'],\n",
      "                            media['img_url'],\n",
      "                            media['likes_count'],\n",
      "                            tag.encode('utf-8')\n",
      "                            ])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for machine in range(number_of_machines):\n",
      "    list_user_id = []\n",
      "    min_user_id = machine * search_space\n",
      "    max_user_id = (machine + 1) * search_space\n",
      "    nmb_users_to_search = 100\n",
      "    \n",
      "    while (nmb_users_to_search > 0):\n",
      "        user_id = generate_user_id(min_user_id, max_user_id)\n",
      "        # Getting media with this user_id\n",
      "        try:\n",
      "            # URL ot get  the most recent media published by a user\n",
      "            url = 'https://api.instagram.com/v1/users/' + str(user_id) +'/media/recent/?client_id=' + CLIENT_ID\n",
      "            data = get_data(url) ['data'] # Taking only photo\n",
      "            # Take only information that need\n",
      "            data_for_storing = modify_data(data)\n",
      "            if data_for_storing: # If we have the data do\n",
      "                save_user_id(user_id)\n",
      "                store_in_big_csv(machine, data_for_storing)\n",
      "                store_in_user_csv(machine, user_id, data_for_storing)\n",
      "                store_data_for_analysis(machine,data_for_storing)\n",
      "                nmb_users_to_search -= 1\n",
      "        except Exception, e:\n",
      "            print e\n",
      "            \n",
      "    store_user_ids(machine, list_user_id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}